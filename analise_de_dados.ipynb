{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099dd406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def create_cycles(df):\n",
    "    # Criar uma máscara onde a válvula está aberta\n",
    "    mask_open = df['valve_open'] == 0\n",
    "\n",
    "    # Aplicar a máscara e identificar blocos consecutivos onde a válvula está aberta\n",
    "    df_open = df[mask_open].copy()\n",
    "    df_open['cycle'] = (df_open.index.to_series().diff() != 1).cumsum()\n",
    "\n",
    "    # Separar os ciclos (apenas quando a válvula está aberta)\n",
    "    open_cycles = [g.reset_index(drop=True) for _, g in df_open.groupby('cycle')]\n",
    "\n",
    "    X = pd.concat(open_cycles)\n",
    "    ciclos_completos = X[~X['cycle'].isin([X['cycle'].min(),X['cycle'].max()])]\n",
    "    return ciclos_completos\n",
    "\n",
    "\n",
    "def plot_samples(df, number=10):\n",
    "    \"\"\"\n",
    "    Plota até `number` curvas da tabela `df`, assumindo que cada coluna é uma amostra\n",
    "    e cada linha representa um tempo.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    colunas = df.columns\n",
    "    for i in range(0,len(colunas),number):\n",
    "        next_step = min(i + number,max(colunas))\n",
    "        df[colunas[i:next_step]].mean(axis=1).plot(label=f'ciclo {i} a {next_step-1}')\n",
    "    ax.legend()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99360aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp_4 = pd.read_csv('./sensor_log_4.csv')\n",
    "df_exp_5 = pd.read_csv('./sensor_log_5.csv')\n",
    "exp_4 = create_cycles(df_exp_4)\n",
    "exp_5 =  create_cycles(df_exp_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd03ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_exp_4 = pd.pivot_table(exp_4,index=exp_4.index,columns='cycle',values='sensor_value') * -1\n",
    "pivot_exp_5 = pd.pivot_table(exp_5,index=exp_5.index,columns='cycle',values='sensor_value') *-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3706fe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de uso:\n",
    "plot = plot_samples(pivot_exp_4, number=20)\n",
    "plot.set_xlabel('Tempo em (s)')\n",
    "plot.set_ylabel('Pressão em (kPa)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49c7587",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_60_exp_4 = pivot_exp_4[pivot_exp_4.columns[3:20]].mean(axis=1)\n",
    "min_60_exp_5 = pivot_exp_5[pivot_exp_5.columns[3:20]].mean(axis=1)\n",
    "\n",
    "min_60_exp_4_all = pivot_exp_4[pivot_exp_4.columns[:]].mean(axis=1)\n",
    "min_60_exp_5_all = pivot_exp_5[pivot_exp_5.columns[:]].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d757b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Gráfico 1: Ambos experimentos \"all\" no mesmo gráfico\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Primeiro subplot - ambas as linhas \"all\" juntas\n",
    "min_60_exp_4_all.plot(ax=ax1, label='Experimento 4 - All')\n",
    "min_60_exp_5_all.plot(ax=ax1, label='Experimento 5 - All')\n",
    "ax1.set_title('Comparação - Todos os dados')\n",
    "ax2.set_xlabel('Tempo em (s)')\n",
    "ax2.set_ylabel('Pressão em (Kpa)')\n",
    "ax1.legend()\n",
    "\n",
    "# Segundo subplot - ambas as linhas normais juntas\n",
    "min_60_exp_4.plot(ax=ax2, label='Experimento 4')\n",
    "min_60_exp_5.plot(ax=ax2, label='Experimento 5')\n",
    "ax2.set_title('Comparação - Primeiros 20 ciclos')\n",
    "ax2.set_xlabel('Tempo em (s)')\n",
    "ax2.set_ylabel('Pressão em (Kpa)')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e24041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Simulação de dados (substitua por seus dados reais)\n",
    "x = min_60_exp_4.index\n",
    "y = min_60_exp_4.values\n",
    "\n",
    "# Modelo exponencial saturado melhorado\n",
    "def modelo_exponencial_saturado(x, a, b, c=0):\n",
    "    \"\"\"\n",
    "    Modelo: y = a * (1 - exp(-b * x)) + c\n",
    "    a: valor de saturação (assíntota)\n",
    "    b: taxa de crescimento\n",
    "    c: offset inicial (opcional)\n",
    "    \"\"\"\n",
    "    return a * (1 - np.exp(-b * x)) + c\n",
    "\n",
    "# Modelo alternativo: Michaelis-Menten\n",
    "def modelo_michaelis_menten(x, vmax, km):\n",
    "    \"\"\"\n",
    "    Modelo: y = (vmax * x) / (km + x)\n",
    "    vmax: valor máximo (saturação)\n",
    "    km: constante de meia-saturação\n",
    "    \"\"\"\n",
    "    return (vmax * x) / (km + x)\n",
    "\n",
    "# Modelo logístico\n",
    "def modelo_logistico(x, L, k, x0):\n",
    "    \"\"\"\n",
    "    Modelo: y = L / (1 + exp(-k * (x - x0)))\n",
    "    L: valor máximo\n",
    "    k: taxa de crescimento\n",
    "    x0: ponto de inflexão\n",
    "    \"\"\"\n",
    "    return L / (1 + np.exp(-k * (x - x0)))\n",
    "\n",
    "# Estimativas iniciais mais inteligentes\n",
    "def estimar_parametros_iniciais(x, y):\n",
    "    \"\"\"Estima parâmetros iniciais baseado nos dados\"\"\"\n",
    "    a_inicial = np.max(y) * 1.1  # 10% acima do máximo observado\n",
    "    \n",
    "    # Estima b baseado na inclinação inicial\n",
    "    if len(y) > 1:\n",
    "        inclinacao_inicial = (y[1] - y[0]) / (x[1] - x[0])\n",
    "        b_inicial = inclinacao_inicial / a_inicial\n",
    "    else:\n",
    "        b_inicial = 0.01\n",
    "    \n",
    "    return a_inicial, max(b_inicial, 0.001)  # garante b positivo\n",
    "\n",
    "# Obter estimativas iniciais\n",
    "a_init, b_init = estimar_parametros_iniciais(x, y)\n",
    "\n",
    "print(\"=== COMPARAÇÃO DE MODELOS ===\\n\")\n",
    "\n",
    "# Modelo 1: Exponencial saturado simples\n",
    "try:\n",
    "    params1, cov1 = curve_fit(\n",
    "        lambda x, a, b: modelo_exponencial_saturado(x, a, b, 0),\n",
    "        x, y, \n",
    "        p0=[a_init, b_init],\n",
    "        bounds=([0, 0], [np.inf, np.inf]),\n",
    "        maxfev=5000\n",
    "    )\n",
    "    a1, b1 = params1\n",
    "    erro_a1, erro_b1 = np.sqrt(np.diag(cov1))\n",
    "    y_pred1 = modelo_exponencial_saturado(x, a1, b1, 0)\n",
    "    r2_1 = r2_score(y, y_pred1)\n",
    "    aic1 = len(y) * np.log(np.sum((y - y_pred1)**2)/len(y)) + 2 * len(params1)\n",
    "    \n",
    "    print(f\"Modelo 1 - Exponencial Saturado: y = {a1:.4f} * (1 - exp(-{b1:.6f} * x))\")\n",
    "    print(f\"R² = {r2_1:.4f}, AIC = {aic1:.2f}\\n\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Erro no Modelo 1: {e}\")\n",
    "    params1, r2_1 = None, 0\n",
    "\n",
    "# Modelo 2: Exponencial saturado com offset\n",
    "try:\n",
    "    params2, cov2 = curve_fit(\n",
    "        modelo_exponencial_saturado,\n",
    "        x, y, \n",
    "        p0=[a_init, b_init, np.min(y)],\n",
    "        maxfev=5000\n",
    "    )\n",
    "    a2, b2, c2 = params2\n",
    "    y_pred2 = modelo_exponencial_saturado(x, a2, b2, c2)\n",
    "    r2_2 = r2_score(y, y_pred2)\n",
    "    aic2 = len(y) * np.log(np.sum((y - y_pred2)**2)/len(y)) + 2 * len(params2)\n",
    "    \n",
    "    print(f\"Modelo 2 - Exponencial c/ Offset: y = {a2:.4f} * (1 - exp(-{b2:.6f} * x)) + {c2:.4f}\")\n",
    "    print(f\"R² = {r2_2:.4f}, AIC = {aic2:.2f}\\n\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Erro no Modelo 2: {e}\")\n",
    "    params2, r2_2 = None, 0\n",
    "\n",
    "# Modelo 3: Michaelis-Menten\n",
    "try:\n",
    "    params3, cov3 = curve_fit(\n",
    "        modelo_michaelis_menten,\n",
    "        x, y, \n",
    "        p0=[np.max(y), np.median(x)],\n",
    "        bounds=([0, 0], [np.inf, np.inf]),\n",
    "        maxfev=5000\n",
    "    )\n",
    "    vmax, km = params3\n",
    "    y_pred3 = modelo_michaelis_menten(x, vmax, km)\n",
    "    r2_3 = r2_score(y, y_pred3)\n",
    "    aic3 = len(y) * np.log(np.sum((y - y_pred3)**2)/len(y)) + 2 * len(params3)\n",
    "    \n",
    "    print(f\"Modelo 3 - Michaelis-Menten: y = ({vmax:.4f} * x) / ({km:.2f} + x)\")\n",
    "    print(f\"R² = {r2_3:.4f}, AIC = {aic3:.2f}\\n\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Erro no Modelo 3: {e}\")\n",
    "    params3, r2_3 = None, 0\n",
    "\n",
    "# Selecionar melhor modelo\n",
    "modelos = [\n",
    "    (\"Exponencial Saturado\", params1, r2_1, y_pred1 if 'y_pred1' in locals() else None),\n",
    "    (\"Exponencial c/ Offset\", params2, r2_2, y_pred2 if 'y_pred2' in locals() else None),\n",
    "    (\"Michaelis-Menten\", params3, r2_3, y_pred3 if 'y_pred3' in locals() else None)\n",
    "]\n",
    "\n",
    "melhor_modelo = max(modelos, key=lambda x: x[2] if x[2] is not None else 0)\n",
    "print(f\"=== MELHOR MODELO: {melhor_modelo[0]} (R² = {melhor_modelo[2]:.4f}) ===\\n\")\n",
    "\n",
    "# Plot melhorado\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Subplot 1: Comparação dos modelos\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.scatter(x, y, alpha=0.7, s=30, label=\"Dados\", color='blue')\n",
    "\n",
    "cores = ['orange', 'red', 'green']\n",
    "for i, (nome, params, r2, y_pred) in enumerate(modelos):\n",
    "    if y_pred is not None:\n",
    "        plt.plot(x, y_pred, '--', linewidth=2, color=cores[i], \n",
    "                label=f\"{nome} (R²={r2:.3f})\")\n",
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Comparação de Modelos\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 2: Resíduos do melhor modelo\n",
    "plt.subplot(2, 2, 2)\n",
    "if melhor_modelo[3] is not None:\n",
    "    residuos = y - melhor_modelo[3]\n",
    "    plt.scatter(melhor_modelo[3], residuos, alpha=0.7)\n",
    "    plt.axhline(y=0, color='red', linestyle='--')\n",
    "    plt.xlabel(\"Valores Preditos\")\n",
    "    plt.ylabel(\"Resíduos\")\n",
    "    plt.title(f\"Resíduos - {melhor_modelo[0]}\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 3: Q-Q plot dos resíduos\n",
    "plt.subplot(2, 2, 3)\n",
    "if melhor_modelo[3] is not None:\n",
    "    from scipy import stats\n",
    "    stats.probplot(residuos, dist=\"norm\", plot=plt)\n",
    "    plt.title(\"Q-Q Plot dos Resíduos\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 4: Histograma dos resíduos\n",
    "plt.subplot(2, 2, 4)\n",
    "if melhor_modelo[3] is not None:\n",
    "    plt.hist(residuos, bins=20, alpha=0.7, edgecolor='black')\n",
    "    plt.xlabel(\"Resíduos\")\n",
    "    plt.ylabel(\"Frequência\")\n",
    "    plt.title(\"Distribuição dos Resíduos\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Tabela de parâmetros do melhor modelo\n",
    "if melhor_modelo[0] == \"Exponencial Saturado\" and params1 is not None:\n",
    "    summary_df = pd.DataFrame({\n",
    "        \"Parâmetro\": [\"a (saturação)\", \"b (taxa)\"],\n",
    "        \"Estimativa\": [a1, b1],\n",
    "        \"Erro padrão\": [erro_a1, erro_b1],\n",
    "        \"Inferior 95%\": [a1 - 1.96 * erro_a1, b1 - 1.96 * erro_b1],\n",
    "        \"Superior 95%\": [a1 + 1.96 * erro_a1, b1 + 1.96 * erro_b1]\n",
    "    })\n",
    "elif melhor_modelo[0] == \"Exponencial c/ Offset\" and params2 is not None:\n",
    "    erro_a2, erro_b2, erro_c2 = np.sqrt(np.diag(cov2))\n",
    "    summary_df = pd.DataFrame({\n",
    "        \"Parâmetro\": [\"a (saturação)\", \"b (taxa)\", \"c (offset)\"],\n",
    "        \"Estimativa\": [a2, b2, c2],\n",
    "        \"Erro padrão\": [erro_a2, erro_b2, erro_c2],\n",
    "        \"Inferior 95%\": [a2 - 1.96 * erro_a2, b2 - 1.96 * erro_b2, c2 - 1.96 * erro_c2],\n",
    "        \"Superior 95%\": [a2 + 1.96 * erro_a2, b2 + 1.96 * erro_b2, c2 + 1.96 * erro_c2]\n",
    "    })\n",
    "elif melhor_modelo[0] == \"Michaelis-Menten\" and params3 is not None:\n",
    "    erro_vmax, erro_km = np.sqrt(np.diag(cov3))\n",
    "    summary_df = pd.DataFrame({\n",
    "        \"Parâmetro\": [\"Vmax (saturação)\", \"Km (meia-saturação)\"],\n",
    "        \"Estimativa\": [vmax, km],\n",
    "        \"Erro padrão\": [erro_vmax, erro_km],\n",
    "        \"Inferior 95%\": [vmax - 1.96 * erro_vmax, km - 1.96 * erro_km],\n",
    "        \"Superior 95%\": [vmax + 1.96 * erro_vmax, km + 1.96 * erro_km]\n",
    "    })\n",
    "\n",
    "print(\"\\n=== PARÂMETROS DO MELHOR MODELO ===\")\n",
    "print(summary_df.to_string(index=False, float_format='%.6f'))\n",
    "\n",
    "# Métricas de qualidade do ajuste\n",
    "print(f\"\\n=== MÉTRICAS DE QUALIDADE ===\")\n",
    "print(f\"R² = {melhor_modelo[2]:.4f}\")\n",
    "if melhor_modelo[3] is not None:\n",
    "    rmse = np.sqrt(np.mean((y - melhor_modelo[3])**2))\n",
    "    mae = np.mean(np.abs(y - melhor_modelo[3]))\n",
    "    print(f\"RMSE = {rmse:.6f}\")\n",
    "    print(f\"MAE = {mae:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67eab9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Simulação de dados (substitua por seus dados reais)\n",
    "x = min_60_exp_5.index\n",
    "y = min_60_exp_5.values\n",
    "\n",
    "# Modelo exponencial saturado melhorado\n",
    "def modelo_exponencial_saturado(x, a, b, c=0):\n",
    "    \"\"\"\n",
    "    Modelo: y = a * (1 - exp(-b * x)) + c\n",
    "    a: valor de saturação (assíntota)\n",
    "    b: taxa de crescimento\n",
    "    c: offset inicial (opcional)\n",
    "    \"\"\"\n",
    "    return a * (1 - np.exp(-b * x)) + c\n",
    "\n",
    "# Modelo alternativo: Michaelis-Menten\n",
    "def modelo_michaelis_menten(x, vmax, km):\n",
    "    \"\"\"\n",
    "    Modelo: y = (vmax * x) / (km + x)\n",
    "    vmax: valor máximo (saturação)\n",
    "    km: constante de meia-saturação\n",
    "    \"\"\"\n",
    "    return (vmax * x) / (km + x)\n",
    "\n",
    "# Modelo logístico\n",
    "def modelo_logistico(x, L, k, x0):\n",
    "    \"\"\"\n",
    "    Modelo: y = L / (1 + exp(-k * (x - x0)))\n",
    "    L: valor máximo\n",
    "    k: taxa de crescimento\n",
    "    x0: ponto de inflexão\n",
    "    \"\"\"\n",
    "    return L / (1 + np.exp(-k * (x - x0)))\n",
    "\n",
    "# Estimativas iniciais mais inteligentes\n",
    "def estimar_parametros_iniciais(x, y):\n",
    "    \"\"\"Estima parâmetros iniciais baseado nos dados\"\"\"\n",
    "    a_inicial = np.max(y) * 1.1  # 10% acima do máximo observado\n",
    "    \n",
    "    # Estima b baseado na inclinação inicial\n",
    "    if len(y) > 1:\n",
    "        inclinacao_inicial = (y[1] - y[0]) / (x[1] - x[0])\n",
    "        b_inicial = inclinacao_inicial / a_inicial\n",
    "    else:\n",
    "        b_inicial = 0.01\n",
    "    \n",
    "    return a_inicial, max(b_inicial, 0.001)  # garante b positivo\n",
    "\n",
    "# Obter estimativas iniciais\n",
    "a_init, b_init = estimar_parametros_iniciais(x, y)\n",
    "\n",
    "print(\"=== COMPARAÇÃO DE MODELOS ===\\n\")\n",
    "\n",
    "# Modelo 1: Exponencial saturado simples\n",
    "try:\n",
    "    params1, cov1 = curve_fit(\n",
    "        lambda x, a, b: modelo_exponencial_saturado(x, a, b, 0),\n",
    "        x, y, \n",
    "        p0=[a_init, b_init],\n",
    "        bounds=([0, 0], [np.inf, np.inf]),\n",
    "        maxfev=5000\n",
    "    )\n",
    "    a1, b1 = params1\n",
    "    erro_a1, erro_b1 = np.sqrt(np.diag(cov1))\n",
    "    y_pred1 = modelo_exponencial_saturado(x, a1, b1, 0)\n",
    "    r2_1 = r2_score(y, y_pred1)\n",
    "    aic1 = len(y) * np.log(np.sum((y - y_pred1)**2)/len(y)) + 2 * len(params1)\n",
    "    \n",
    "    print(f\"Modelo 1 - Exponencial Saturado: y = {a1:.4f} * (1 - exp(-{b1:.6f} * x))\")\n",
    "    print(f\"R² = {r2_1:.4f}, AIC = {aic1:.2f}\\n\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Erro no Modelo 1: {e}\")\n",
    "    params1, r2_1 = None, 0\n",
    "\n",
    "# Modelo 2: Exponencial saturado com offset\n",
    "try:\n",
    "    params2, cov2 = curve_fit(\n",
    "        modelo_exponencial_saturado,\n",
    "        x, y, \n",
    "        p0=[a_init, b_init, np.min(y)],\n",
    "        maxfev=5000\n",
    "    )\n",
    "    a2, b2, c2 = params2\n",
    "    y_pred2 = modelo_exponencial_saturado(x, a2, b2, c2)\n",
    "    r2_2 = r2_score(y, y_pred2)\n",
    "    aic2 = len(y) * np.log(np.sum((y - y_pred2)**2)/len(y)) + 2 * len(params2)\n",
    "    \n",
    "    print(f\"Modelo 2 - Exponencial c/ Offset: y = {a2:.4f} * (1 - exp(-{b2:.6f} * x)) + {c2:.4f}\")\n",
    "    print(f\"R² = {r2_2:.4f}, AIC = {aic2:.2f}\\n\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Erro no Modelo 2: {e}\")\n",
    "    params2, r2_2 = None, 0\n",
    "\n",
    "# Modelo 3: Michaelis-Menten\n",
    "try:\n",
    "    params3, cov3 = curve_fit(\n",
    "        modelo_michaelis_menten,\n",
    "        x, y, \n",
    "        p0=[np.max(y), np.median(x)],\n",
    "        bounds=([0, 0], [np.inf, np.inf]),\n",
    "        maxfev=5000\n",
    "    )\n",
    "    vmax, km = params3\n",
    "    y_pred3 = modelo_michaelis_menten(x, vmax, km)\n",
    "    r2_3 = r2_score(y, y_pred3)\n",
    "    aic3 = len(y) * np.log(np.sum((y - y_pred3)**2)/len(y)) + 2 * len(params3)\n",
    "    \n",
    "    print(f\"Modelo 3 - Michaelis-Menten: y = ({vmax:.4f} * x) / ({km:.2f} + x)\")\n",
    "    print(f\"R² = {r2_3:.4f}, AIC = {aic3:.2f}\\n\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Erro no Modelo 3: {e}\")\n",
    "    params3, r2_3 = None, 0\n",
    "\n",
    "# Selecionar melhor modelo\n",
    "modelos = [\n",
    "    (\"Exponencial Saturado\", params1, r2_1, y_pred1 if 'y_pred1' in locals() else None),\n",
    "    (\"Exponencial c/ Offset\", params2, r2_2, y_pred2 if 'y_pred2' in locals() else None),\n",
    "    (\"Michaelis-Menten\", params3, r2_3, y_pred3 if 'y_pred3' in locals() else None)\n",
    "]\n",
    "\n",
    "melhor_modelo = max(modelos, key=lambda x: x[2] if x[2] is not None else 0)\n",
    "print(f\"=== MELHOR MODELO: {melhor_modelo[0]} (R² = {melhor_modelo[2]:.4f}) ===\\n\")\n",
    "\n",
    "# Plot melhorado\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Subplot 1: Comparação dos modelos\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.scatter(x, y, alpha=0.7, s=30, label=\"Dados\", color='blue')\n",
    "\n",
    "cores = ['orange', 'red', 'green']\n",
    "for i, (nome, params, r2, y_pred) in enumerate(modelos):\n",
    "    if y_pred is not None:\n",
    "        plt.plot(x, y_pred, '--', linewidth=2, color=cores[i], \n",
    "                label=f\"{nome} (R²={r2:.3f})\")\n",
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Comparação de Modelos\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 2: Resíduos do melhor modelo\n",
    "plt.subplot(2, 2, 2)\n",
    "if melhor_modelo[3] is not None:\n",
    "    residuos = y - melhor_modelo[3]\n",
    "    plt.scatter(melhor_modelo[3], residuos, alpha=0.7)\n",
    "    plt.axhline(y=0, color='red', linestyle='--')\n",
    "    plt.xlabel(\"Valores Preditos\")\n",
    "    plt.ylabel(\"Resíduos\")\n",
    "    plt.title(f\"Resíduos - {melhor_modelo[0]}\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 3: Q-Q plot dos resíduos\n",
    "plt.subplot(2, 2, 3)\n",
    "if melhor_modelo[3] is not None:\n",
    "    from scipy import stats\n",
    "    stats.probplot(residuos, dist=\"norm\", plot=plt)\n",
    "    plt.title(\"Q-Q Plot dos Resíduos\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 4: Histograma dos resíduos\n",
    "plt.subplot(2, 2, 4)\n",
    "if melhor_modelo[3] is not None:\n",
    "    plt.hist(residuos, bins=20, alpha=0.7, edgecolor='black')\n",
    "    plt.xlabel(\"Resíduos\")\n",
    "    plt.ylabel(\"Frequência\")\n",
    "    plt.title(\"Distribuição dos Resíduos\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Tabela de parâmetros do melhor modelo\n",
    "if melhor_modelo[0] == \"Exponencial Saturado\" and params1 is not None:\n",
    "    summary_df = pd.DataFrame({\n",
    "        \"Parâmetro\": [\"a (saturação)\", \"b (taxa)\"],\n",
    "        \"Estimativa\": [a1, b1],\n",
    "        \"Erro padrão\": [erro_a1, erro_b1],\n",
    "        \"Inferior 95%\": [a1 - 1.96 * erro_a1, b1 - 1.96 * erro_b1],\n",
    "        \"Superior 95%\": [a1 + 1.96 * erro_a1, b1 + 1.96 * erro_b1]\n",
    "    })\n",
    "elif melhor_modelo[0] == \"Exponencial c/ Offset\" and params2 is not None:\n",
    "    erro_a2, erro_b2, erro_c2 = np.sqrt(np.diag(cov2))\n",
    "    summary_df = pd.DataFrame({\n",
    "        \"Parâmetro\": [\"a (saturação)\", \"b (taxa)\", \"c (offset)\"],\n",
    "        \"Estimativa\": [a2, b2, c2],\n",
    "        \"Erro padrão\": [erro_a2, erro_b2, erro_c2],\n",
    "        \"Inferior 95%\": [a2 - 1.96 * erro_a2, b2 - 1.96 * erro_b2, c2 - 1.96 * erro_c2],\n",
    "        \"Superior 95%\": [a2 + 1.96 * erro_a2, b2 + 1.96 * erro_b2, c2 + 1.96 * erro_c2]\n",
    "    })\n",
    "elif melhor_modelo[0] == \"Michaelis-Menten\" and params3 is not None:\n",
    "    erro_vmax, erro_km = np.sqrt(np.diag(cov3))\n",
    "    summary_df = pd.DataFrame({\n",
    "        \"Parâmetro\": [\"Vmax (saturação)\", \"Km (meia-saturação)\"],\n",
    "        \"Estimativa\": [vmax, km],\n",
    "        \"Erro padrão\": [erro_vmax, erro_km],\n",
    "        \"Inferior 95%\": [vmax - 1.96 * erro_vmax, km - 1.96 * erro_km],\n",
    "        \"Superior 95%\": [vmax + 1.96 * erro_vmax, km + 1.96 * erro_km]\n",
    "    })\n",
    "\n",
    "print(\"\\n=== PARÂMETROS DO MELHOR MODELO ===\")\n",
    "print(summary_df.to_string(index=False, float_format='%.6f'))\n",
    "\n",
    "# Métricas de qualidade do ajuste\n",
    "print(f\"\\n=== MÉTRICAS DE QUALIDADE ===\")\n",
    "print(f\"R² = {melhor_modelo[2]:.4f}\")\n",
    "if melhor_modelo[3] is not None:\n",
    "    rmse = np.sqrt(np.mean((y - melhor_modelo[3])**2))\n",
    "    mae = np.mean(np.abs(y - melhor_modelo[3]))\n",
    "    print(f\"RMSE = {rmse:.6f}\")\n",
    "    print(f\"MAE = {mae:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71adc1e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctt_futuro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
